---
title: "Study Log"
date: 2019. 11. 29. 오후 8:32:38
categories:
use_math: true
classes: wide
---

# 2019-12-10
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 4. Dynamic Programming
    * 4.2 Policy Improvement
    * 4.3 Policy Iteration
    * 
  * Page #

---

# 2019-12-04
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 3. Finite Markov Decision Processes
    * 3.1 The Agent–Environment Interface
    * 3.2 Goals and Rewards
    * 3.3 Returns and Episodes
    * 3.4 Unified Notation for Episodic and Continuing Tasks
    * 3.5 Policies and Value Functions
    * 3.6 Optimal Policies and Optimal Value Functions
    * 3.7 Optimality and Approximation
    * 3.8 Summary
  * Chapter 4. Dynamic Programming
    * 4.1 Policy Evaluation (Prediction)
    * 4.2 Policy Improvement
  * Page #79

---

# 2019-12-03
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 2. Multi-armed Bandits
    * 2.7 Upper-Confidence-Bound Action Selection
    * 2.8 Gradient Bandit Algorithms
    * 2.9 Associative Search (Contextual Bandits)
    * 2.10 Summary
  * Page #47

---

# 2019-12-02
* [모두를 위한 머신러닝/딥러닝 강의](http://hunkim.github.io/ml/)
  * [Lecture #30) lec10-1: Sigmoid 보다 ReLU가 더 좋아](https://www.youtube.com/watch?v=cKtg_fpw88c&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=31&t=0s)
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 1. Introduction
    * 1.4 Limitations and Scope
    * 1.5 An Extended Example: Tic-Tac-Toe
    * 1.6 Summary
  * Chapter 2. Multi-armed Bandits
    * 2.1 A k-armed Bandit Problem
    * 2.2 Action-value Methods
    * 2.3 The 10-armed Testbed
    * 2.4 Incremental Implementation
    * 2.5 Tracking a Nonstationary Problem
    * 2.6 Optimistic Initial Values
  * Page #35

---

# 2019-12-01
* [Fundamental of Reinforcement Learning](https://dnddnjs.gitbook.io/rl/)
  * Chapter 4. Dynamic Programming
  * Chapter 5. Monte-Carlo Methods
* [모두를 위한 머신러닝/딥러닝 강의](http://hunkim.github.io/ml/)
  * [Lecture #25) lec9-1: XOR 문제 딥러닝으로 풀기](https://www.youtube.com/watch?v=GYecDQQwTdI&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=26&t=0s)
  * Lecture #26
  * Lecture #27
  * Lecture #28
  * Lecture #29
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 1. Introduction
    * 1.1 Reinforcement Learning
    * 1.2 Examples
    * 1.3 Elements of Reinforcement Learning
  * Page #7

---

# 2019-11-30
* [모두를 위한 머신러닝/딥러닝 강의](http://hunkim.github.io/ml/)
  * [Lecture #14) ML lec 6-1 - Softmax Regression: 기본 개념 소개](https://www.youtube.com/watch?v=MFAnsx1y9ZI&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=14)
  * Lecture #15
  * Lecture #16
  * Lecture #17
  * Lecture #18
  * Lecture #19
  * Lecture #20
  * Lecture #21
  * Lecture #22
  * Lecture #23
  * Lecture #24
* [파이썬과 케라스로 배우는 강화학습](https://missflash.github.io/python-keras-rl/)
  * 7. 강화학습 심화 3: 아타리

---

# 2019-11-29
* [강화학습 관련 자료](https://github.com/reinforcement-learning-kr/how_to_study_rl/wiki/강화학습-관련-자료)
  * [자료 정리](https://github.com/missflash/missflash.github.io/wiki/Deep-Self-Learning)
* [Fundamental of Reinforcement Learning](https://dnddnjs.gitbook.io/rl/)
  * Chapter 1. Introduction
  * Chapter 2. Markov Decision Process
  * Chapter 3. Bellman Equation

---

# Template
* [Fundamental of Reinforcement Learning](https://dnddnjs.gitbook.io/rl/)
  * Chapter #.
* [모두를 위한 머신러닝/딥러닝 강의](http://hunkim.github.io/ml/)
  * Lecture #.
* [UCL Course on RL](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
  * Lecture #.
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Page #.

---

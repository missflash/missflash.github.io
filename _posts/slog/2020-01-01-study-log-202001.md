---
title: "Study Log (2020.01)"
date: 2020. 01. 01. 오후 10:57:38
categories:
use_math: true
classes: wide
---

# 2020-01-20
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 11. Off-policy Methods with Approximation
    * 11.2 Examples of Off-policy Divergence
    * 11.3 The Deadly Triad
    * 11.4 Linear Value-function Geometry
    * 11.5 Gradient Descent in the Bellman Error
  * Page #272

---

# 2020-01-19
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 11. Off-policy Methods with Approximation
    * 11.2 Examples of Off-policy Divergence
  * Page #263

---

# 2020-01-18
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 11. Off-policy Methods with Approximation
    * 11.2 Examples of Off-policy Divergence
  * Page #262

---

# 2020-01-17
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 11. Off-policy Methods with Approximation
    * 11.1 Semi-gradient Methods
    * 11.2 Examples of Off-policy Divergence
  * Page #260

---

# 2020-01-16
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 10. On-policy Control with Approximation
    * 10.5 Differential Semi-gradient n-step Sarsa
    * 10.6 Summary
  * Page #257

---

# 2020-01-15
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 10. On-policy Control with Approximation
    * 10.3 Average Reward: A New Problem Setting for Continuing Tasks
      * [access_control.py](https://github.com/missflash/reinforcement-learning-an-introduction/blob/master/chapter10/access_control.py)
    * 10.4 Deprecating the Discounted Setting
  * Page #255

---

# 2020-01-14
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 10. On-policy Control with Approximation
    * 10.2 Semi-gradient n-step Sarsa
      * [Mountain Car with gradient SARSA](https://github.com/missflash/Reinforcement-Learning-Implementation/blob/master/MountainCar/MountainCar.ipynb)
    * 10.3 Average Reward: A New Problem Setting for Continuing Tasks
  * Page #252

---

# 2020-01-13
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 9. On-policy Prediction with Approximation
    * 9.9 Memory-based Function Approximation
    * 9.10 Kernel-based Function Approximation
    * 9.11 Looking Deeper at On-policy Learning: Interest and Emphasis
    * 9.12 Summary
  * Chapter 10. On-policy Control with Approximation
    * 10.1 Episodic Semi-gradient Control
    * 10.2 Semi-gradient n-step Sarsa
  * Page #247

---

# 2020-01-11
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 9. On-policy Prediction with Approximation
    * 9.7 Nonlinear Function Approximation: Artificial Neural Networks
    * 9.8 Least-Squares TD
  * Page #228

---

# 2020-01-10
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 9. On-policy Prediction with Approximation
    * 9.5 Feature Construction for Linear Methods
      * 9.5.5 Radial Basis Functions
    * 9.6 Selecting Step-Size Parameters Manually
  * Page #223

---

# 2020-01-09
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 9. On-policy Prediction with Approximation
    * 9.5 Feature Construction for Linear Methods
      * 9.5.4 Tile Coding
  * Page #220
* [Feature Construction for Linear Methods](https://talkingaboutme.tistory.com/entry/RL-Feature-Construction-for-Linear-Methods)

---

# 2020-01-08
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 9. On-policy Prediction with Approximation
    * 9.4 Linear Methods
    * 9.5 Feature Construction for Linear Methods
      * 9.5.1 Polynomials
      * 9.5.2 Fourier Basis
      * 9.5.3 Coarse Coding
  * Page #217

---

# 2020-01-07
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 9. On-policy Prediction with Approximation
    * 9.3 Stochastic-gradient and Semi-gradient Methods
      * [RandomWalk(General)](https://github.com/missflash/Reinforcement-Learning-Implementation/blob/master/RandomWalk(General)/RandomWalk.py)
    * 9.4 Linear Methods
  * Page #205
* [모두를 위한 머신러닝/딥러닝 강의](http://hunkim.github.io/ml/)
  * [Lecture #42) ML lab12-1: RNN - Basics](https://www.youtube.com/watch?v=B5GtZuUvujQ&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm&index=43&t=0s)
  * Lecture #43
  * Lecture #44

---

# 2020-01-06
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 9. On-policy Prediction with Approximation
    * 9.2 The Prediction Objective (VE)
    * 9.3 Stochastic-gradient and Semi-gradient Methods
      * [random_walk.py](https://github.com/missflash/reinforcement-learning-an-introduction/blob/master/chapter09/random_walk.py)
      * [Reinforcement Learning — Generalisation in Continuous State Space](https://towardsdatascience.com/reinforcement-learning-generalisation-in-continuous-state-space-df943b04ebfa)
  * Page #204

---

# 2020-01-05
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 9. On-policy Prediction with Approximation
    * 9.1 Value-function Approximation
  * Page #199

---

# 2020-01-04
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 8. Planning and Learning with Tabular Methods
    * 8.7 Real-time Dynamic Programming
    * 8.8 Planning at Decision Time
      * [Planning and Learning with Tabular Methods](https://www.slideshare.net/DongMinLee32/planning-and-learning-with-tabular-methods)
    * 8.9 Heuristic Search
    * 8.10 Rollout Algorithms
    * 8.11 Monte Carlo Tree Search
    * 8.12 Summary of the Chapter
    * 8.13 Summary of Part I: Dimensions
  * Page #195

---

# 2020-01-03
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 8. Planning and Learning with Tabular Methods
    * 8.5 Expected vs. Sample Updates<br>
      ![Backup Diagrams](https://raw.githubusercontent.com/missflash/missflash.github.io/master/_files/Backup Diagrams.png){: width="50%" height="50%"}
      * [All About Backup Diagram](https://towardsdatascience.com/all-about-backup-diagram-fefb25aaf804)
    * 8.6 Trajectory Sampling
    * 8.7 Real-time Dynamic Programming
  * Page #179

---

# 2020-01-02
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 8. Planning and Learning with Tabular Methods
    * 8.4 Prioritized Sweeping
      * [Priority Sweeping](https://github.com/missflash/Reinforcement-Learning-Implementation/blob/master/DynaMaze/PrioritySweeping.ipynb)
    * 8.5 Expected vs. Sample Updates
  * Page #173

---

# 2020-01-01
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Chapter 8. Planning and Learning with Tabular Methods
    * 8.3 When the Model Is Wrong
      * [Reinforcement Learning - Model Based Planning Methods Extension](https://towardsdatascience.com/reinforcement-learning-model-based-planning-methods-extension-572dfee4cceb)
      * [Dyna-Q+](https://github.com/missflash/Reinforcement-Learning-Implementation/blob/master/DynaMaze/DynaMaze.ipynb)
    * 8.4 Prioritized Sweeping
  * Page #172

---

# Template
* [Fundamental of Reinforcement Learning](https://dnddnjs.gitbook.io/rl/)
  * Chapter #.
* [모두를 위한 머신러닝/딥러닝 강의](http://hunkim.github.io/ml/)
  * Lecture #.
* [UCL Course on RL](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
  * Lecture #.
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Page #.
* [팡요랩](https://www.youtube.com/playlist?list=PLpRS2w0xWHTcTZyyX8LMmtbcMXpd3s4TU)
  * Lecture #.
* [Pattern Recognition & Machine Learning](http://norman3.github.io/prml/)

---

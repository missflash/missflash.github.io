---
title: "Study Log (2021.12)"
date: 2021. 12. 1. 오후 5:13:30
categories:
use_math: true
classes: wide
---

# 2021-12-29
* [모델 성능 개선으로 익히는 강화학습 A-Z](https://fastcampus.co.kr/data_online_rein)
  * Part 2. 가치기반 강화학습의 풀이법
    * Ch 03. 모델없이 세상 알아가기
      * 05\. TD 를 활용한 정책추정 실습

---

# 2021-12-28
* [단단한 강화학습](http://www.yes24.com/Product/Goods/89605439)
  * Ch 04. 동적 프로그래밍
    * 4.7 동적 프로그래밍의 효율성
    * 4.8 요약

---

# 2021-12-27
* [단단한 강화학습](http://www.yes24.com/Product/Goods/89605439)
  * Ch 04. 동적 프로그래밍
    * 4.4 가치 반복
    * 4.5 비동기 동적 프로그래밍
    * 4.6 일반화된 정책 반복

---

# 2021-12-26
* [단단한 강화학습](http://www.yes24.com/Product/Goods/89605439)
  * Ch 04. 동적 프로그래밍
    * 4.1 정책 평가(예측)
    * 4.2 정책 향상
    * 4.3 정책 반복

---

# 2021-12-25
* [단단한 강화학습](http://www.yes24.com/Product/Goods/89605439)
  * Ch 03. 유한 마르코프 결정 과정
    * 3.5 정책과 가치 함수
    * 3.6 최적 정책과 최적 가치 함수
    * 3.7 최적성과 근사
    * 3.8 요약

---

# 2021-12-24
* [모델 성능 개선으로 익히는 강화학습 A-Z](https://fastcampus.co.kr/data_online_rein)
  * Part 2. 가치기반 강화학습의 풀이법
    * Ch 03. 모델없이 세상 알아가기
      * 04\. Temporal Difference (TD) 정책추정
* [단단한 강화학습](http://www.yes24.com/Product/Goods/89605439)
  * Ch 03. 유한 마르코프 결정 과정
    * 3.1 에이전트-환경 인터페이스
    * 3.2 목표와 보상
    * 3.3 보상과 에피소드
    * 3.4 에피소딕 작업과 연속적인 작업을 위한 통합 표기법

---

# 2021-12-23
* [모델 성능 개선으로 익히는 강화학습 A-Z](https://fastcampus.co.kr/data_online_rein)
  * Part 2. 가치기반 강화학습의 풀이법
    * Ch 03. 모델없이 세상 알아가기
      * 03. 몬테카를로 정책추정 실습
* [단단한 강화학습](http://www.yes24.com/Product/Goods/89605439)
  * Ch 02. 다중 선택
    * 2.1 다중 선택 문제
    * 2.2 행동 가치 방법
    * 2.3 10중 선택 테스트
    * 2.4 점증적 구현
    * 2.5 비정상 문제의 흔적
    * 2.6 긍정적 초기값
    * 2.7 신뢰 상한 행동 선택
    * 2.8 경사도 다중 선택 알고리즘
    * 2.9 연관 탐색(맥락적 다중 선택)
    * 2.10 요약

---

# 2021-12-22
* [모델 성능 개선으로 익히는 강화학습 A-Z](https://fastcampus.co.kr/data_online_rein)
  * Part 2. 가치기반 강화학습의 풀이법
    * Ch 03. 모델없이 세상 알아가기
      * 01. 도박의 도시 몬테카를로 (MC) 그리고 MC 정책추정 - 1
      * 02. 도박의 도시 몬테카를로 (MC) 그리고 MC 정책추정 - 2

---

# 2021-12-21
* [모델 성능 개선으로 익히는 강화학습 A-Z](https://fastcampus.co.kr/data_online_rein)
  * Part 2. 가치기반 강화학습의 풀이법
    * Ch 02. 동적 계획법
      * 04. DP 실습 2 - 정책반복, 가치반복
      * 05. DP 실습 3 비동기적 DP
* [단단한 강화학습](http://www.yes24.com/Product/Goods/89605439)
  * Ch 01. 소개
    * 1.1 강화학습
    * 1.2 예제
    * 1.3 강화학습의 구성 요소
    * 1.4 한계와 범위
    * 1.5 확장된 예제: 틱택토
    * 1.6 요약
    * 1.7 강화학습의 초기 역사
  * Ch 02. 다중 선택
    * 2.1 다중 선택 문제
    * 2.2 행동 가치 방법
    * 2.3 10중 선택 테스트
    * 2.4 점증적 구현
    * 2.5 비정상 문제의 흔적
    * 2.6 긍정적 초기값
    * 2.7 신뢰 상한 행동 선택
    * 2.8 경사도 다중 선택 알고리즘
    * 2.9 연관 탐색(맥락적 다중 선택)
    * 2.10 요약

---

# 2021-12-20
* [모델 성능 개선으로 익히는 강화학습 A-Z](https://fastcampus.co.kr/data_online_rein)
  * Part 2. 가치기반 강화학습의 풀이법
    * Ch 02. 동적 계획법
      * 01. 강화학습의 근간 - 동적계획법
      * 02. DP 실습 1 - 정책평가와 정책개선
      * 03. 더 효율적인 DP - 비동기적 동적계획법

---

# 2021-12-17
* [모델 성능 개선으로 익히는 강화학습 A-Z](https://fastcampus.co.kr/data_online_rein)
  * Part 2. 가치기반 강화학습의 풀이법
    * Ch 01. 마르코프 결정과정
      * 01. 강화학습의 놀이터 - MP, MRP
      * 02. 강화학습의 놀이터 - MDP
      * 03. MDP 실습 - Gridworld 로 알아보는 MDP

---

# 2021-12-16
* [모델 성능 개선으로 익히는 강화학습 A-Z](https://fastcampus.co.kr/data_online_rein)
  * Part 1. 강화학습 소개
    * 01. 강화학습 소개 - '강화'학습이 무엇인가요 어디에 쓸수 있죠
    * 02. 강화학습에 쓰이는 수식 읽기 - 강.대.넓.얕 강화학습 대화를 위한 넓고 얕은 수식
    * 03. 강화학습 환경 설정 -강화학습 구현을 위한 환경설정

---

# 2021-12-01
* S-K RL
  * train_FT10_ppo_node_only.py
    * do_simulate_on_aggregated_state()
    * value_loss, action_loss, dist_entropy = agent.fit(eval=0, reward_setting='utilization', device=device, return_scaled=False)
    * eval_performance = evaluate_agent_on_aggregated_state(simulator=sim, agent=agent, device='cpu', mode='node_mode')
    * val_performance = validation(agent, path, mode='node_mode')
  * pyjssp 버전 구분
    * GNN-MARL Lastest용
    * GNN-MARL Stable용

---

# Template
* [Fundamental of Reinforcement Learning](https://dnddnjs.gitbook.io/rl/)
  * Chapter #.
* [모두를 위한 머신러닝/딥러닝 강의](http://hunkim.github.io/ml/)
  * Lecture #.
* [UCL Course on RL](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
  * Lecture #.
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Page #.
* [팡요랩](https://www.youtube.com/playlist?list=PLpRS2w0xWHTcTZyyX8LMmtbcMXpd3s4TU)
  * [강화학습 1강 - 강화학습 introduction](https://www.youtube.com/watch?v=wYgyiCEkwC8)
  * [강화학습 2강 - Markov Decision Process](https://www.youtube.com/watch?v=NMesGSXr8H4)
  * [강화학습 3강 - Planning by Dynamic Programming](https://www.youtube.com/watch?v=rrTxOkbHj-M)
  * [강화학습 4강 - Model Free Prediction](https://www.youtube.com/watch?v=47FyZtBRglI)
  * [강화학습 5강 - Model Free Control](https://www.youtube.com/watch?v=2h-FD3e1YgQ)
  * [강화학습 6강 - Value Function Approximation](https://www.youtube.com/watch?v=71nH1BUjhNw)
  * [강화학습 7강 - Policy Gradient](https://www.youtube.com/watch?v=2YFBordM1fA)
  * [강화학습 8강 - Integrating Learning and Planning](https://www.youtube.com/watch?v=S216ZLuCdM0)
  * [강화학습 9강 - Exploration and Exploitation](https://www.youtube.com/watch?v=nm6RwuA_pGE)
  * [강화학습 10강 - Classic Games](https://www.youtube.com/watch?v=C5_2v4pRc5c)
* [Pattern Recognition & Machine Learning](http://norman3.github.io/prml/)
* S-K RL
* multi_step_actor

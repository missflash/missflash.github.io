---
title: "Study Log (2021.01)"
date: 2021. 1. 1. 오후 5:13:30
categories:
use_math: true
classes: wide

---

# 2021-01-31
* S-K RL
  * train_FT10_ppo_node_only.py
    * do_simulate_on_aggregated_state()
    * value_loss, action_loss, dist_entropy = agent.fit(eval=0, reward_setting='utilization', device=device, return_scaled=False)
    * eval_performance = evaluate_agent_on_aggregated_state(simulator=sim, agent=agent, device='cpu', mode='node_mode')
    * val_performance = validation(agent, path, mode='node_mode')
  * SBJSSP_report_results.ipynb
    * def get_swapping_ops(blocking_op, machine_dict)
    * class blMachine(Machine)
    * class blMachineManager(MachineManager)
    * class blSimulator(Simulator)
    * def evaluate_agent_on_aggregated_state(simulator, agent, device, mode='edge_mode')
    * def evaluate_agent_on_aggregated_state_DR(simulator, mode='MTWR')
    * def SBJSSP_validation(agent, path, device='cpu', optimums=None, num_val=100, new_attr=False, mode='edge_mode', special=None, DR=None)
    * def compare_with_optimum(makespans, files, plot=False, scheduler_name=None)
    * def evaluate_agent_on_aggregated_state_DR_interrupted(simulator, mode='MTWR', shutdown_prob=0.2)
    * def evaluate_agent_on_aggregated_state_interrupted(simulator, agent, device, mode='edge_mode', shutdown_prob=0.2)
    * def SBJSSP_validation_interrupted(agent, path, device='cpu', optimums=None, num_val=100, new_attr=False, mode='edge_mode', special=None, DR=None, shutdown_prob=0.2)
    * def random_simulator(min_m=5, max_m=10, max_job=10, new_attr=False, special='SBJSSP'):
    * def do_simulate_on_aggregated_state_interrupted(simulator, agent, episode_index, device, reward='utilization', scaled=False, mode='edge_mode',shutdown_prob=0.2)
* [팡요랩](https://www.youtube.com/playlist?list=PLpRS2w0xWHTcTZyyX8LMmtbcMXpd3s4TU)
  * [강화학습 3강 - Planning by Dynamic Programming](https://www.youtube.com/watch?v=rrTxOkbHj-M)

---

# 2021-01-30
* S-K RL
  * train_FT10_ppo_node_only.py
    * pyjssp > benchmarks.py
    * pyjssp > simulators.py
    * pyjssp > jobShopSamplers.py
    * pyjssp > operationHelpers.py
    * src > node_only_agents.py
    * src/agents.py
    * src/rl_networks.py
    * torch > linear.py
    * src/training_utils.py
    * src/utils.py
    * src > nn.py
* [팡요랩](https://www.youtube.com/playlist?list=PLpRS2w0xWHTcTZyyX8LMmtbcMXpd3s4TU)
  * [강화학습 2강 - Markov Decision Process](https://www.youtube.com/watch?v=NMesGSXr8H4)

---

# 2021-01-29
* S-K RL
  * train_FT10_ppo_node_only.py
    * pyjssp > benchmarks.py
    * pyjssp > simulators.py
    * pyjssp > jobShopSamplers.py
    * pyjssp > operationHelpers.py
    * src > node_only_agents.py
    * src/agents.py
    * src/rl_networks.py
    * torch > linear.py
    * src/training_utils.py
    * src/utils.py
    * src > nn.py
* [팡요랩](https://www.youtube.com/playlist?list=PLpRS2w0xWHTcTZyyX8LMmtbcMXpd3s4TU)
  * [강화학습 1강 - 강화학습 introduction](https://www.youtube.com/watch?v=wYgyiCEkwC8)

---

# 2021-01-01
* S-K RL
  * train_FT10_ppo_node_only.py
    * pyjssp > benchmarks.py
    * pyjssp > simulators.py
    * pyjssp > jobShopSamplers.py
    * pyjssp > operationHelpers.py
    * src > node_only_agents.py
    * src/agents.py
    * src/rl_networks.py
    * torch > linear.py
    * src/training_utils.py
    * src/utils.py
    * src > nn.py

---

# Template
* [Fundamental of Reinforcement Learning](https://dnddnjs.gitbook.io/rl/)
  * Chapter #.
* [모두를 위한 머신러닝/딥러닝 강의](http://hunkim.github.io/ml/)
  * Lecture #.
* [UCL Course on RL](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
  * Lecture #.
* [Reinforcement Learning](http://incompleteideas.net/book/the-book-2nd.html)
  * Page #.
* [팡요랩](https://www.youtube.com/playlist?list=PLpRS2w0xWHTcTZyyX8LMmtbcMXpd3s4TU)
  * [강화학습 1강 - 강화학습 introduction](https://www.youtube.com/watch?v=wYgyiCEkwC8)
  * [강화학습 2강 - Markov Decision Process](https://www.youtube.com/watch?v=NMesGSXr8H4)
  * [강화학습 3강 - Planning by Dynamic Programming](https://www.youtube.com/watch?v=rrTxOkbHj-M)
  * [강화학습 4강 - Model Free Prediction](https://www.youtube.com/watch?v=47FyZtBRglI)
  * [강화학습 5강 - Model Free Control](https://www.youtube.com/watch?v=2h-FD3e1YgQ)
  * [강화학습 6강 - Value Function Approximation](https://www.youtube.com/watch?v=71nH1BUjhNw)
  * [강화학습 7강 - Policy Gradient](https://www.youtube.com/watch?v=2YFBordM1fA)
  * [강화학습 8강 - Integrating Learning and Planning](https://www.youtube.com/watch?v=S216ZLuCdM0)
  * [강화학습 9강 - Exploration and Exploitation](https://www.youtube.com/watch?v=nm6RwuA_pGE)
  * [강화학습 10강 - Classic Games](https://www.youtube.com/watch?v=C5_2v4pRc5c)
* [Pattern Recognition & Machine Learning](http://norman3.github.io/prml/)
* S-K RL
* multi_step_actor
